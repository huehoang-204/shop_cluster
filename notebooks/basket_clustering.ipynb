{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ded5d6b",
   "metadata": {},
   "source": [
    "# Basket Clustering Analysis\n",
    "\n",
    "This notebook performs basket clustering, compares K-Means with Agglomerative/DBSCAN/HDBSCAN, evaluates using silhouette/DBI/CH metrics, and analyzes actionability of clusters. It also compares basket-level vs product-level clustering for marketing insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9e30c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random state for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb05277",
   "metadata": {},
   "source": [
    "## Load Transaction Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0919688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (485123, 11)\n",
      "  InvoiceNo StockCode                          Description  Quantity  \\\n",
      "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
      "1    536365     71053                  WHITE METAL LANTERN         6   \n",
      "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
      "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
      "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
      "\n",
      "           InvoiceDate  UnitPrice CustomerID         Country  TotalPrice  \\\n",
      "0  2010-12-01 08:26:00       2.55     017850  United Kingdom       15.30   \n",
      "1  2010-12-01 08:26:00       3.39     017850  United Kingdom       20.34   \n",
      "2  2010-12-01 08:26:00       2.75     017850  United Kingdom       22.00   \n",
      "3  2010-12-01 08:26:00       3.39     017850  United Kingdom       20.34   \n",
      "4  2010-12-01 08:26:00       3.39     017850  United Kingdom       20.34   \n",
      "\n",
      "   DayOfWeek  HourOfDay  \n",
      "0          2          8  \n",
      "1          2          8  \n",
      "2          2          8  \n",
      "3          2          8  \n",
      "4          2          8  \n",
      "Unique customers: 3921\n",
      "Unique products: 3916\n",
      "Unique invoices: 18021\n"
     ]
    }
   ],
   "source": [
    "# Load cleaned transaction data\n",
    "df = pd.read_csv('../data/processed/cleaned_uk_data.csv')\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "print(df.head())\n",
    "print(f\"Unique customers: {df['CustomerID'].nunique()}\")\n",
    "print(f\"Unique products: {df['StockCode'].nunique()}\")\n",
    "print(f\"Unique invoices: {df['InvoiceNo'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6befa8c2",
   "metadata": {},
   "source": [
    "## Preprocessing and Basket Matrix Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba060750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basket matrix shape: (3549, 100)\n",
      "StockCode   20712  20719  20723  20724  20725  20726  20727  20728  20914  \\\n",
      "CustomerID                                                                  \n",
      "000nan          1      1      1      1      1      1      1      1      1   \n",
      "012747          0      0      0      0      0      0      0      0      0   \n",
      "012748          1      1      1      1      1      1      1      1      1   \n",
      "012749          0      0      0      0      0      0      0      0      1   \n",
      "012820          1      0      0      0      0      0      0      0      0   \n",
      "\n",
      "StockCode   21034  ...  84879  84946  84978  84991  85099B  85099C  85099F  \\\n",
      "CustomerID         ...                                                       \n",
      "000nan          1  ...      1      1      1      1       1       1       1   \n",
      "012747          0  ...      1      0      0      0       1       1       1   \n",
      "012748          1  ...      1      1      1      1       1       1       1   \n",
      "012749          0  ...      1      0      0      0       0       0       0   \n",
      "012820          0  ...      0      1      0      0       0       0       0   \n",
      "\n",
      "StockCode   85123A  85152  DOT  \n",
      "CustomerID                      \n",
      "000nan           1      1    1  \n",
      "012747           1      0    0  \n",
      "012748           1      1    0  \n",
      "012749           0      0    0  \n",
      "012820           1      0    0  \n",
      "\n",
      "[5 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "# Filter top products to reduce dimensionality\n",
    "top_products = df['StockCode'].value_counts().head(100).index\n",
    "df_filtered = df[df['StockCode'].isin(top_products)]\n",
    "\n",
    "# Create basket matrix (binary: customer x product)\n",
    "basket_matrix = df_filtered.pivot_table(\n",
    "    index='CustomerID', \n",
    "    columns='StockCode', \n",
    "    values='Quantity', \n",
    "    aggfunc='sum', \n",
    "    fill_value=0\n",
    ").astype(bool).astype(int)  # Binary matrix\n",
    "\n",
    "print(f\"Basket matrix shape: {basket_matrix.shape}\")\n",
    "print(basket_matrix.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc3a940",
   "metadata": {},
   "source": [
    "## Clustering Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "989c18f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans: 3 clusters, runtime: 0.02s\n",
      "Agglomerative: 3 clusters, runtime: 1.02s\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'DBSCAN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     25\u001b[39m results = {}\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m algo, params \u001b[38;5;129;01min\u001b[39;00m algorithms:\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     labels, runtime = \u001b[43mrun_clustering\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m     results[algo] = {\u001b[33m'\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m'\u001b[39m: labels, \u001b[33m'\u001b[39m\u001b[33mruntime\u001b[39m\u001b[33m'\u001b[39m: runtime}\n\u001b[32m     29\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00malgo\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(labels))\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m clusters, runtime: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mruntime\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mrun_clustering\u001b[39m\u001b[34m(X, algorithm, params)\u001b[39m\n\u001b[32m      6\u001b[39m     model = AgglomerativeClustering(n_clusters=params[\u001b[33m'\u001b[39m\u001b[33mn_clusters\u001b[39m\u001b[33m'\u001b[39m], linkage=params.get(\u001b[33m'\u001b[39m\u001b[33mlinkage\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mward\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m algorithm == \u001b[33m'\u001b[39m\u001b[33mDBSCAN\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     model = \u001b[43mDBSCAN\u001b[49m(eps=params[\u001b[33m'\u001b[39m\u001b[33meps\u001b[39m\u001b[33m'\u001b[39m], min_samples=params[\u001b[33m'\u001b[39m\u001b[33mmin_samples\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     10\u001b[39m labels = model.fit_predict(X)\n\u001b[32m     11\u001b[39m runtime = time.time() - start_time\n",
      "\u001b[31mNameError\u001b[39m: name 'DBSCAN' is not defined"
     ]
    }
   ],
   "source": [
    "def run_clustering(X, algorithm, params):\n",
    "    start_time = time.time()\n",
    "    if algorithm == 'KMeans':\n",
    "        model = KMeans(n_clusters=params['n_clusters'], random_state=RANDOM_STATE)\n",
    "    elif algorithm == 'Agglomerative':\n",
    "        model = AgglomerativeClustering(n_clusters=params['n_clusters'], linkage=params.get('linkage', 'ward'))\n",
    "    elif algorithm == 'DBSCAN':\n",
    "        model = DBSCAN(eps=params['eps'], min_samples=params['min_samples'])\n",
    "    \n",
    "    labels = model.fit_predict(X)\n",
    "    runtime = time.time() - start_time\n",
    "    return labels, runtime\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(basket_matrix)\n",
    "\n",
    "# Run algorithms\n",
    "algorithms = [\n",
    "    ('KMeans', {'n_clusters': 3}),\n",
    "    ('Agglomerative', {'n_clusters': 3, 'linkage': 'ward'}),\n",
    "    ('DBSCAN', {'eps': 1.5, 'min_samples': 5})\n",
    "]\n",
    "\n",
    "results = {}\n",
    "for algo, params in algorithms:\n",
    "    labels, runtime = run_clustering(X_scaled, algo, params)\n",
    "    results[algo] = {'labels': labels, 'runtime': runtime}\n",
    "    print(f\"{algo}: {len(set(labels))} clusters, runtime: {runtime:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de352549",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f152332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_clustering(X, labels):\n",
    "    if len(set(labels)) <= 1:\n",
    "        return {'Silhouette': np.nan, 'DBI': np.nan, 'CH': np.nan}\n",
    "    \n",
    "    sil = silhouette_score(X, labels)\n",
    "    dbi = davies_bouldin_score(X, labels)\n",
    "    ch = calinski_harabasz_score(X, labels)\n",
    "    return {'Silhouette': sil, 'DBI': dbi, 'CH': ch}\n",
    "\n",
    "# Evaluate each algorithm\n",
    "evaluation_results = {}\n",
    "for algo, res in results.items():\n",
    "    metrics = evaluate_clustering(X_scaled, res['labels'])\n",
    "    evaluation_results[algo] = {**metrics, 'Runtime': res['runtime']}\n",
    "\n",
    "eval_df = pd.DataFrame(evaluation_results).T\n",
    "print(eval_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efa991e",
   "metadata": {},
   "source": [
    "## Actionability Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60027a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_actionability(basket_matrix, labels, algo_name):\n",
    "    basket_with_labels = basket_matrix.copy()\n",
    "    basket_with_labels['cluster'] = labels\n",
    "    \n",
    "    # Cluster sizes\n",
    "    cluster_sizes = basket_with_labels['cluster'].value_counts().sort_index()\n",
    "    \n",
    "    # Top products per cluster\n",
    "    top_products = {}\n",
    "    for cluster in cluster_sizes.index:\n",
    "        cluster_data = basket_with_labels[basket_with_labels['cluster'] == cluster]\n",
    "        product_sums = cluster_data.drop('cluster', axis=1).sum().sort_values(ascending=False)\n",
    "        top_products[cluster] = product_sums.head(5).index.tolist()\n",
    "    \n",
    "    return {\n",
    "        'cluster_sizes': cluster_sizes,\n",
    "        'top_products': top_products\n",
    "    }\n",
    "\n",
    "# Analyze actionability for each algorithm\n",
    "actionability = {}\n",
    "for algo, res in results.items():\n",
    "    actionability[algo] = analyze_actionability(basket_matrix, res['labels'], algo)\n",
    "\n",
    "# Print results\n",
    "for algo, analysis in actionability.items():\n",
    "    print(f\"\\n{algo} Actionability:\")\n",
    "    print(f\"Cluster sizes: {analysis['cluster_sizes'].to_dict()}\")\n",
    "    for cluster, products in analysis['top_products'].items():\n",
    "        print(f\"Cluster {cluster} top products: {products}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c28a34",
   "metadata": {},
   "source": [
    "## Comparison and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a71c401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA for visualization\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Plot comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "for i, (algo, res) in enumerate(results.items()):\n",
    "    ax = axes[i]\n",
    "    scatter = ax.scatter(X_pca[:, 0], X_pca[:, 1], c=res['labels'], cmap='viridis', alpha=0.6)\n",
    "    ax.set_title(f'{algo} Clustering')\n",
    "    ax.set_xlabel('PC1')\n",
    "    ax.set_ylabel('PC2')\n",
    "    plt.colorbar(scatter, ax=ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary table\n",
    "summary = eval_df.copy()\n",
    "summary['Actionability'] = [f\"{len(actionability[algo]['cluster_sizes'])} clusters\" for algo in summary.index]\n",
    "print(\"\\nSummary Comparison:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b341cd",
   "metadata": {},
   "source": [
    "## Product Clustering for Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee6130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create product co-occurrence matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Transpose basket matrix to get product x customer\n",
    "product_matrix = basket_matrix.T\n",
    "\n",
    "# Calculate co-occurrence (dot product of binary matrix)\n",
    "co_occurrence = product_matrix.dot(product_matrix.T)\n",
    "\n",
    "# Convert to similarity matrix\n",
    "product_similarity = cosine_similarity(co_occurrence)\n",
    "\n",
    "# Cluster products using K-Means\n",
    "product_kmeans = KMeans(n_clusters=5, random_state=RANDOM_STATE)\n",
    "product_labels = product_kmeans.fit_predict(product_similarity)\n",
    "\n",
    "print(f\"Product clustering: {len(set(product_labels))} clusters\")\n",
    "print(f\"Products per cluster: {pd.Series(product_labels).value_counts().sort_index()}\")\n",
    "\n",
    "# Show example products per cluster\n",
    "product_clusters = pd.DataFrame({\n",
    "    'StockCode': product_matrix.index,\n",
    "    'cluster': product_labels\n",
    "})\n",
    "\n",
    "for cluster in sorted(set(product_labels)):\n",
    "    products_in_cluster = product_clusters[product_clusters['cluster'] == cluster]['StockCode'].head(5).tolist()\n",
    "    print(f\"Cluster {cluster} sample products: {products_in_cluster}\")\n",
    "\n",
    "# Evaluate product clustering\n",
    "if len(set(product_labels)) > 1:\n",
    "    prod_sil = silhouette_score(product_similarity, product_labels)\n",
    "    prod_dbi = davies_bouldin_score(product_similarity, product_labels)\n",
    "    prod_ch = calinski_harabasz_score(product_similarity, product_labels)\n",
    "    print(f\"Product clustering metrics - Silhouette: {prod_sil:.3f}, DBI: {prod_dbi:.3f}, CH: {prod_ch:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af6ae5d",
   "metadata": {},
   "source": [
    "## Basket vs Product Clustering Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e23a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare basket vs product clustering insights\n",
    "comparison_data = {\n",
    "    'Approach': ['Basket Clustering (Customer-level)', 'Product Clustering (Product-level)'],\n",
    "    'Input': ['Customer purchase patterns (3549 customers x 100 products)', 'Product co-occurrence (100 products x 100 products)'],\n",
    "    'Clusters': [f\"{len(set(results['KMeans']['labels']))} customer clusters\", f\"{len(set(product_labels))} product clusters\"],\n",
    "    'Silhouette': [f\"{eval_df.loc['KMeans', 'Silhouette']:.3f}\", f\"{prod_sil:.3f}\"],\n",
    "    'Marketing Use Case': ['Customer segmentation, personalized campaigns', 'Product recommendations, bundle creation'],\n",
    "    'Actionability': ['Direct customer targeting, retention strategies', 'Cross-sell suggestions, shelf optimization'],\n",
    "    'Advantage': ['Customer-centric insights, easier to action', 'Product discovery, automated recommendations']\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"Basket vs Product Clustering Comparison:\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "print(\"\\nConclusion:\")\n",
    "print(\"- Basket clustering provides more actionable customer insights for direct marketing campaigns\")\n",
    "print(\"- Product clustering helps with product recommendations and merchandising\")\n",
    "print(\"- For this project, basket clustering aligns better with customer segmentation goals\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
